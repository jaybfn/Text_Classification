{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb01cd1e",
   "metadata": {},
   "source": [
    "# Importing all the necessary libraries for scraping lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7469e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622bf90",
   "metadata": {},
   "source": [
    "## Defining a function to extract song names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2468fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_name(List):\n",
    "    \n",
    "    \"\"\" This function has multiple parts:\n",
    "        It need an input 'List'is a list of all table row tags from an artists page.\n",
    "        steps:\n",
    "        1. extracts text from the tag which contains song name\n",
    "        2. removes any text which is enclosed in '()' and '[]' \n",
    "        3. removes any special characters within the text\n",
    "        4. Concatinates'.txt' as a file extension to song name\n",
    "        5. Removes duplicate filenames form the file\n",
    "        \"\"\"\n",
    "    \n",
    "    song_name = []\n",
    "    for name in List:\n",
    "        name = name.get_text() \n",
    "        song_name.append(name)\n",
    "    # regex pattern to extract parenthesis and square bracket with texts store in them\n",
    "    Song_Name_pattern = '[\\(\\[].*?[\\)\\]]'   \n",
    "    file_names_list =[]\n",
    "    for i in song_name:\n",
    "        file_names = re.sub(pattern=Song_Name_pattern, string= i, repl=\"\"  )\n",
    "        file_names_list.append(file_names)\n",
    "    \n",
    "    # to remove special character from the text    \n",
    "    character = '[^0-9a-zA-Z]' \n",
    "    final_file_name = []\n",
    "    for i in file_names_list:\n",
    "    \n",
    "        file_names_final = re.sub(pattern=character, string= i, repl=\"\"  )\n",
    "        final_file_name.append(file_names_final)\n",
    "    \n",
    "    # generating a list of filename with .txt extension\n",
    "    filenames = [] \n",
    "    for name in final_file_name:\n",
    "        filename =name+'.txt'\n",
    "        filenames.append(filename)\n",
    "\n",
    "    # removes duplicate songs.\n",
    "    #filenames = list(set(filenames))\n",
    "    return filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa7caf",
   "metadata": {},
   "source": [
    "## Lyrics Extraction from Lyrics.com and save each lyrics into individual 'songname.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a70bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many artists lyrics you want to scrap:1\n",
      "Artist_1:x\n"
     ]
    }
   ],
   "source": [
    "header = {'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'}\n",
    "URL = 'https://www.lyrics.com/' #to scrap lyrics from this page\n",
    "page = requests.get(URL, headers=header)\n",
    "\n",
    "\n",
    "#************************************************************************\n",
    "# this part of codes prompts user to input 2 parameters:\n",
    "# 1. how many artist lyrics he wants to scrap.\n",
    "# 2. Entering the artist names as shown in the webpage of lyrics.com.\n",
    "# Also the user can control the number of artist he want to scrap even after entering a particular number during \n",
    "# the first prompt. \n",
    "    # eg: A user wish to enter 5 artist name, so he types in 5 during the first prompt, then the program starts asking the user\n",
    "        # to enter the artist name one by one, in case he wants to only have 3 artist lyrics to be scraped while entering the \n",
    "        # artist's name, then he can type 'x' on the next prompt to exit the loop.\n",
    "        \n",
    "number_of_artists = (int(input(f'How many artists lyrics you want to scrap:')))\n",
    "\n",
    "artistlist = []\n",
    "for i in range(number_of_artists):\n",
    "    j = i+1\n",
    "    name = str(input(f'Artist_{j}:'))\n",
    "    if name != 'x':\n",
    "        artistlist.append(name)\n",
    "    else:\n",
    "        break\n",
    "#************************************************************************\n",
    "\n",
    "search = 'artist'    \n",
    "#artistlist = ['CKay','Curtis-Mayfield']#input the artist names as netioned in the lyrics.com\n",
    "artistlist_path =['/'+ item for item in artistlist]#concatinates '/'to the artist names for accessing the html page\n",
    "\n",
    "#artistname_folder = [ch.replace(\"/\", \"\") for ch in artistlist]#\n",
    "\n",
    "# for loop for extracting all the lyrics links for artist names\n",
    "for name, folder_name in zip(artistlist_path, artistlist):\n",
    "    #*****************************************************************************\n",
    "    # this part of the code makes a directory with artist names and also checks if directory \n",
    "    # already exists or not\n",
    "    if os.path.isdir(folder_name):\n",
    "        path = os.getcwd()+name \n",
    "        os.chdir(path)\n",
    "        #pass\n",
    "    else:\n",
    "        directory = os.mkdir(folder_name) #creates a folder with artist name\n",
    "        path = os.getcwd()+name \n",
    "        os.chdir(path)\n",
    "    #*****************************************************************************\n",
    "    \n",
    "    response = requests.get(URL+search+name, headers=header)\n",
    "    get_a_tag = response.text # extract text from the html file\n",
    "    cont = response.content\n",
    "    soup = BeautifulSoup(cont, 'html.parser') # to soupout all the content \n",
    "    tag = soup.find_all('td', {'class':'tal qx'}) # to extract a particula tag from a html page which contains the link to the lyrics\n",
    "    \n",
    "    # regex for extracting the link\n",
    "    pattern = '\\/lyric\\/\\w+[^\"]+' \n",
    "    links = re.findall(pattern=pattern,string=get_a_tag,flags=re.IGNORECASE ) # function to find all the links in the html content\n",
    "    \n",
    "    #**********************************************************\n",
    "    # this part of code removes duplicate lyrics\n",
    "    final_file_names = [] #initilizing filne names as .txt \n",
    "    for i in get_song_name(tag):\n",
    "        final_file_names.append(i)#.lower()\n",
    "    Links_df = pd.DataFrame(zip(final_file_names,links), columns=['final_file_names','links'] )\n",
    "    #Links_df.drop_duplicates(subset =\"final_file_names\",keep = False, inplace = True)\n",
    "    #os.chdir('../')\n",
    "    #**********************************************************\n",
    "    \n",
    "# for loop to strip all the lyrics (only texts) and save them into a individual file.\n",
    "    # get_song_name() is a custom function to extrac song names from html table cell tag.\n",
    "\n",
    "    for lnk ,name in zip(Links_df['links'],Links_df['final_file_names']):#links,get_song_name(tag)\n",
    "\n",
    "        URL_lyrics = URL+lnk\n",
    "        lyrics_responce = requests.get(URL_lyrics, headers=header)\n",
    "        lyric_cont = lyrics_responce.content\n",
    "        lyric_soup = BeautifulSoup(lyric_cont, 'html.parser')\n",
    "        lyric = lyric_soup.find_all('pre', {'id':'lyric-body-text'})\n",
    "\n",
    "        for txt in lyric:\n",
    "            full_text = txt.get_text()\n",
    "            file = open(name,\"w\", encoding= 'utf-8')    \n",
    "            file.write(full_text)    \n",
    "            file.close()\n",
    "    os.chdir('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad4206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
